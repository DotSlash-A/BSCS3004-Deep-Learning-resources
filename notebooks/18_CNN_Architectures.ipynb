{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Some concepts behind CNNs**\n",
    "- **Sparse-connectivity:**\n",
    "  - A single element in the feature map is connected to only a small patch of pixels\n",
    "  - This is unlike Multilayer perceptrons where all layers were fully connected\n",
    "  - Basically, neighbouring pixels are related\n",
    "- **Parameter-sharing:**\n",
    "  - Same weights are used for different patches of the input image\n",
    "  - Essentially, same filters work for different parts of the image\n",
    "- **Many layers:**\n",
    "  - Combining extracted local patterns to global patterns\n",
    "\n",
    "These assumptions and restrictions are called **Inductive biases** which help CNNs learn more quickly and generalize better (unlike fully-connected networks). We also reduce the training data which is required.\n",
    "\n",
    "Also, convolutional layers are pretty small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What goes wrong in a fully-connected Multilayer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.layers = torch.nn.Sequential(\n",
    "      # 1st hidden layer\n",
    "      torch.nn.Linear(3 * 224 * 224, 10000),  # Input of 224x224 size (3 colour channels) [3*224*224*10000 + 10000(bias) = 1,505,290,000]\n",
    "      torch.nn.ReLU(),\n",
    "\n",
    "      # 2nd hidden layer\n",
    "      torch.nn.Linear(10000, 1000),           # [10000 * 1000 + 1000 = 10,001,000]\n",
    "      torch.nn.ReLU(),\n",
    "\n",
    "      # 3rd hidden layer\n",
    "      torch.nn.Linear(1000, 100),             # [1000 * 100 + 100 = 100,100]\n",
    "      torch.nn.ReLU(),\n",
    "\n",
    "      # output layer\n",
    "      torch.nn.Linear(100, 10)                # [100 * 10 + 10 = 1,010]\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):                       # In total: 1,515,392,110 parameters\n",
    "    x = torch.flatten(x, start_dim = 1)\n",
    "    logits = self.layer(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 5.645GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29827/1101737098.py:7: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  size += sys.getsizeof(param.storage()) / 1024 ** 3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "size = 0\n",
    "mlp = MLP()\n",
    "\n",
    "for name, param in mlp.named_parameters():\n",
    "  size += sys.getsizeof(param.storage()) / 1024 ** 3\n",
    "\n",
    "print(f\"Model size: {size:.3f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing CNN of the above piece of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.cnn_layers = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(3, 8, kernel_size = 5, stride = 2),   # 3 * 5 * 5 * 8 + 8 = 608\n",
    "      torch.nn.ReLU(),\n",
    "\n",
    "      torch.nn.Conv2d(8, 24, kernel_size = 5, stride = 2),  # 8 * 5 * 5 * 24 + 24 = 4,824\n",
    "      torch.nn.ReLU(),\n",
    "\n",
    "      torch.nn.Conv2d(24, 32, kernel_size = 3, stride = 2), # 24 * 3 * 3 * 32 + 32 = 6,944\n",
    "      torch.nn.ReLU(),\n",
    "\n",
    "      torch.nn.Conv2d(32, 48, kernel_size = 3, stride = 2), # 32 * 3 * 3 * 48 + 48 = 13,872\n",
    "      torch.nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.fc_layers = torch.nn.Sequential(\n",
    "      torch.nn.Linear(48 * 12 * 12, 200),                   # 48 * 12 * 12 * 200 + 200 = 1,382,600\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Linear(200, 10)                              # 200 * 10 + 10 = 2,010\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):                                     # In total: 1,410,858\n",
    "    x = self.cnn_layers(x)\n",
    "    x = torch.flatten(x, start_dim = 1)\n",
    "    logits = self.fc_layers(x)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.005GB\n"
     ]
    }
   ],
   "source": [
    "size = 0\n",
    "cnn = CNN()\n",
    "\n",
    "for name, param in cnn.named_parameters():\n",
    "  size += sys.getsizeof(param.storage()) / 1024 ** 3\n",
    "\n",
    "print(f\"Model size: {size:.3f}GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
